---
output: html_document
editor_options: 
  chunk_output_type: console
---

# Data Manipulation

Mastering data manipulation and processing techniques in R is essential for anyone working in data analysis or data science. The ability to clean, transform, and prepare data efficiently is crucial to ensure that analysis results are accurate and reliable. Moreover, mastering these techniques saves time and increases productivity.

## Importing External Files

Two of the most common formats for storing not-so-large datasets are `csv` and `xlsx`.

When loading data from CSV files in R, two commonly used options are the `read.csv()` and `read_csv()` functions. Both are effective for importing tabular data but have significant differences. The `read.csv()` function is a standard option in base R, being simple to use and widely known. On the other hand, `read_csv()` is part of the `readr` package, offering optimized performance and automatic data type detection. While `read.csv()` tends to be slower, especially with large datasets, `read_csv()` is faster and more accurate, capable of maintaining column names as symbols and properly handling data, including empty strings.

```{r eval=FALSE}
# Using read.csv()
data_read_csv <- read.csv("data.csv")

# Using read_csv() from the readr package
library(readr)
data_readr <- read_csv("data.csv")
```

To import data from an Excel file (`xlsx` format) in R, we can use the `readxl` library. First, you need to install it using the command `install.packages("readxl")`. Then, you can use the `read_excel()` function to read the data. For example:

```{r eval=FALSE}
library(readxl)
data <- read_excel("file.xlsx")
```

::: {.callout-tip title="Setting Your Working Directory"}
It is good practice to set a working directory in your R scripts because it helps keep things organized and makes it easier to access data files and results. By setting a working directory, you ensure that all files referenced in your scripts will be easily found without needing to specify long absolute paths.

To set the working directory in R, you can use the `setwd()` function. For example, if you want to set the directory to "C:/MyDirectory", you can do the following:

```{r eval=FALSE}
setwd("C:/MyDirectory")
```

You can also set the directory using the RStudio interface. Simply select "Session" from the menu, then "Set Working Directory," and finally "Choose Directory." This will open a dialog box where you can navigate to the desired directory and select it. After selecting the directory, it will become the current working directory.
:::

## The tidyverse Package

The `tidyverse` package is a collection of R packages designed to work seamlessly and intuitively for data analysis. It includes a variety of powerful and popular packages such as `ggplot2`, `dplyr`, `tidyr`, `tibble`, `readr`, `purrr`, `forcats`, and `stringr`. Each package in the tidyverse is designed to handle a specific step of the data analysis workflow, from importing and cleaning to visualization and modeling. All packages in the `tidyverse` share a common underlying design philosophy, grammar, and data structures. Learn more [on the package page](https://www.tidyverse.org/).

## The `|>` Pipe Operator

The `|>` operator, known as the pipe, is a powerful tool in R that facilitates chaining operations in sequence. It allows you to write code more clearly and concisely, especially when working with tidyverse packages. The pipe takes the result of an expression on the left and passes it as the first argument to the next expression on the right.

::: callout-tip
You don't need to type `|>` every time you need it. Use the shortcut Ctrl+Shift+M.
:::

Suppose we have a function `f`, a function `g`, and a variable `x`. We want to apply `g` to `x`, and then apply `f` to the result. Here’s how we could do this in two ways: using the traditional chained approach and using the `|>` pipe.

```{r eval=FALSE}
result <- f(g(x))

x |> 
  g() |>
  f()
```

Both methods will produce the same result. However, the second approach using the `|>` pipe is more readable and easier to understand, especially when chaining multiple operations. This makes the code more concise and closer to a natural reading of the operation being performed.

::: callout-tip
A good practice when using the `|>` pipe is to break the line after each pipe to improve code readability.
:::

## Data in *Tidy* Format

> "Tidy datasets are all alike, but every messy dataset is messy in its own way." --- Hadley Wickham.

The same dataset can be represented in various ways. See the code below that shows the same data in three different formats.

```{r echo=FALSE, message=FALSE, warning=FALSE}
library(tidyverse)
```

```{r}
table1
table2
table4a
```

All of the above representations are of the same data, but they are not equally easy to use. `table1`, for example, will be much more accessible for working within the tidyverse due to its organization in the *tidy* format. There are three interrelated rules that characterize a dataset in *tidy* format:

1. Each variable is a column; each column represents a variable.
2. Each observation is a row; each row represents an observation.
3. Each value is a cell; each cell contains a single value.

The figure below graphically represents this concept.

![Image from the R4DS book.](img/tidy-1.png)

Pivoting data is the process of reorganizing a dataset to make it compatible with the *tidy* format. This involves transforming the data from a wider format to a longer format, or vice versa, to ensure that each variable corresponds to a column and each observation to a row.

In the example below, we are transforming the data from `table2` to a wider format, where each unique value of the variable `type` becomes a new column. Note that each unit of information (country, year, cases, and count) is split into two rows. This operation makes the data table wider, ensuring that each unit of data is represented in a single row.

```{r}
table2 |> 
  pivot_wider(names_from="type", values_from="count")
```

In the example below, we are transforming the data from `table4a` to a longer format, where the columns representing specific years (1999 and 2000) are gathered into a single column called `year`, and the corresponding values are placed in a new column called `cases`. In this case, the information about years was stored as column names, but according to the *tidy* data principle, they should be in columns. Therefore, we use the `pivot_longer` function.

```{r}
table4a |> 
  pivot_longer(cols = c(`1999`, `2000`), names_to = "year", values_to = "cases")
```

The two functions `pivot_wider` and `pivot_longer` are sufficient for transforming datasets into *tidy* format.

## Main Verbs of the `dplyr` Package

The `dplyr` package is one of the most powerful tools for data manipulation in the R environment. It offers a cohesive set of functions that simplify common manipulation tasks such as filtering, selecting, grouping, sorting, and summarizing data. `dplyr` uses an intuitive and consistent syntax, making it easy to write clean and readable code.

Let’s study the functionality of the main verbs of the package. To illustrate, we will use the `gapminder` dataset. It is a collection of socioeconomic information for various countries over time. See @gapminder. It includes variables such as life expectancy, GDP per capita, infant mortality rate, and population size for different countries and years, covering several decades.

To load the `gapminder` dataset, you need to load the `gapminder` package. With the gapminder package loaded, the `gapminder` dataset will be available for use in your R environment:

```{r results='hide'}
library(gapminder)
head(gapminder)
```

The `glimpse()` function provides a quick and concise overview of the structure of a dataset. When applied to a dataset, like gapminder, it displays essential information about the variables present, including the number of rows, columns, and the first few rows of the dataset:

```{r}
glimpse(gapminder)
```

### select

The `select()` verb is used to select specific columns from a dataset. With `select()`, you can choose the desired columns based on their names, data types, or other criteria.

For example, considering the gapminder dataset, suppose we want to select only the columns referring to the year, country, life expectancy, and GDP per capita. We can do this as follows:

```{r eval=FALSE}
# Selecting columns by name
gapminder |>
  select(year, country, lifeExp, gdpPercap)

# Selecting only numeric columns
gapminder |> 
  select(where(is.numeric))

# Selecting columns that start with "co"
gapminder |> 
  select(starts_with("co"))
```

Note that in the above examples, none of the selections was saved to a variable. To save the selections to a variable, you can assign the result of each `select()` operation to a separate variable. For example:

```{r eval=FALSE}
gapminder_character <- gapminder |> 
  select(where(is.character))
```

### arrange

The verb `arrange()` is used to reorder the rows of a dataset based on the values of one or more columns. When applied to a dataset, `arrange()` sorts the rows in ascending or descending order based on the specified column values.

In the first example using the verb `select()`, we can sort the data by country in alphabetical order as follows:

```{r}
gapminder |>
  select(year, country, lifeExp, gdpPercap, pop) |>
  arrange(country)
```

In the example below, we are organizing the data by year in ascending order and life expectancy in descending order within each year.

```{r}
gapminder |>
  select(year, country, lifeExp, gdpPercap, pop) |>
  arrange(year, desc(lifeExp))
```

::: callout-tip
When using the verb `select()` with the prefix `-`, you can specify the columns you want to **exclude** from the dataset. In the example below, we exclude the `continent` column from the selection.

```{r}
gapminder |> 
  select(-continent)
```
:::

### filter

To analyze specific data of interest, it is often necessary to filter the dataset to include only relevant observations. The verb `filter()` is used for this purpose. Simply define one or more logical conditions that the rows of the dataset must satisfy to be displayed.

In the example below, we filter the data to include only observations where the country is either Brazil or Argentina.

```{r}
gapminder |>
  select(year, country, lifeExp, gdpPercap, pop) |>
  arrange(year, desc(lifeExp)) |> 
  filter(country == "Brazil" | country == "Argentina")
```

### mutate

The verb `mutate()` is used to create or modify columns in an existing dataset. It allows adding new variables calculated based on existing variables or modifying existing variables according to specific logic.

For example, we can use `mutate()` to calculate a new variable representing the total GDP of each country by multiplying per capita GDP by population size. Here's an example of how to do this with the `gapminder` dataset:

```{r}
gapminder_total_gdp <- gapminder |>
  select(country, year, lifeExp, gdpPercap, pop) |>
  mutate(total_gdp = gdpPercap * pop)
```

### summarise

The verb `summarise()` is used to summarize data into a single row, usually by calculating summary statistics such as mean, sum, median, etc. It allows calculating statistical summaries in a dataset, creating a new table containing the summarized results.

Here is an example of how to use `summarise()` to calculate the average life expectancy using the `gapminder` dataset:

```{r}
gapminder |>
  summarise(mean_lifeExp = mean(lifeExp, na.rm = TRUE))
```

### group by {#sec-dados-groupby}

The verb `group_by()` is used to split data into groups based on the values of one or more variables. It does not perform calculations by itself but changes the behavior of summary functions, such as `summarise()`, to operate separately on each group.

Here is an example of how to use `group_by()` with the `gapminder` data to calculate the average life expectancy by continent:

```{r}
gapminder |>
  group_by(continent) |>
  summarise(mean_lifeExp = mean(lifeExp, na.rm = TRUE))
```

The example below uses all the main verbs of `dplyr` to calculate the average life expectancy and the average GDP (in thousands) by continent in the year 2007.

```{r}
gapminder |>
  select(country, continent, year, lifeExp, gdpPercap) |> 
  filter(year == 2007) |> # data only for the year 2007
  mutate(gdp = gdpPercap / 1000) |> # represents per capita GDP in thousands
  group_by(continent) |> # group the data by continent
  summarise(mean_lifeExp = mean(lifeExp, na.rm = TRUE), # average life expectancy
            mean_gdp = mean(gdp, na.rm = TRUE)) |> # average per capita GDP in billions
  arrange(desc(mean_lifeExp))
```

The graph below shows the evolution of average life expectancy in the continents over the years.

```{r echo=FALSE, warning=FALSE, message=FALSE}
library(ggplot2)

gapminder |>
  select(country, continent, year, lifeExp, gdpPercap) |> 
  # filter(year == 2007) |> # data only for the year 2007
  mutate(gdp = gdpPercap / 1000) |> # represents per capita GDP in thousands
  group_by(year,continent) |> # group the data by continent
  summarise(mean_lifeExp = mean(lifeExp, na.rm = TRUE), # average life expectancy
            mean_gdp = mean(gdp, na.rm = TRUE)) |> # average per capita GDP in billions
  arrange(desc(mean_lifeExp)) |> 
  ggplot(aes(year, mean_lifeExp,color=continent))+
  geom_line()+
  geom_point()+
  scale_color_brewer(palette = 'Set1')+
  labs(x="Year", y="Average Life Expectancy", color="Continent")+
  ggplot2::theme_bw()
```

::: {.callout-tip title="Challenge"}
What change was made to the code of the previous example to construct the data used in this graph?
:::

<!-- TODO: add about lubridate-->

<!-- ## Working with dates -->

<!-- TODO: add helpers -->

## Helper Functions

Introducing auxiliary functions from the `dplyr` package that can be very useful in various contexts.

- `pull`, `distinct`, `unite`, `separate_wider_delim`, and the family of `slice_*` functions.

```{r}

gapminder |> 
  filter(year == 1952) |> 
  pull(continent)

gapminder |> 
  distinct(continent)

gapminder |> 
  slice(1:10)

gapminder |> 
  slice_head(n = 5)

gapminder |> 
  slice_tail(n = 5)

set.seed(1)
gapminder |> 
  slice_sample(n = 10)

gapminder |> 
  filter(year == 2007) |> 
  slice_max(lifeExp, n = 2)

gapminder |> 
  filter(year == 2007) |> 
  slice_min(lifeExp, n = 2)

gapminder |> 
  filter(year == 2007 | year == 1952) |> 
  group_by(year) |> 
  slice_max(lifeExp, n = 2)

gapminder_united <- gapminder |> 
  unite("country_continent", c(country, continent),
        sep = "_",
        remove = TRUE,
        na.rm = FALSE)

gapminder_united |>
  separate_wider_delim(country_continent,
                       delim = "_",
                       names = c("country", "continent"))
```

## Exercises {#sec-ex-dados}

Let's work with the `billboard` dataset. In this dataset, each observation is a song. The first three columns (artist, track, and date entered) are variables that describe the song. Then, we have 76 columns (wk1-wk76) that describe the song's ranking each week. Here, the column names are a variable (the week), and the cell values are another (the ranking).

```{r}
library(tidyverse)
billboard
```

**a)** Apply a transformation to the dataset to leave it in the format below.

```{r echo=FALSE}
billboard |> 
  pivot_longer(
    cols = starts_with("wk"), 
    names_to = "week", 
    values_to = "rank"
  )
```

**b)** Observe the result of item **a)**. What happens if a song is in the top 100 for less than 76 weeks? Take the song "Baby Don't Cry" by 2 Pac, for example. The output above suggests that it was in the top 100 for only 7 weeks, and all remaining weeks are filled with missing values (`NA`). These NAs actually do not represent unknown observations; they were forced to exist by the structure of the dataset. Change the code used in **a)** to remove these `NA`s. Answer: How many rows are left? (Hint: see the documentation of the `pivot_longer` function.)

```{r eval=FALSE, echo=FALSE}
#answer
billboard |> 
  pivot_longer(
    cols = starts_with("wk"), 
    names_to = "week", 
    values_to = "rank",
    values_drop_na = TRUE
  )
```

**c)** You may have noticed that in the result of item **a)**, the type of the `week` column is character. Perform the appropriate transformation to obtain a column with numerical values.

```{r echo=FALSE, eval=FALSE}
#answer
billboard_longer <- billboard |> 
  pivot_longer(
    cols = starts_with("wk"), 
    names_to = "week", 
    values_to = "rank",
    values_drop_na = TRUE
  ) |> 
  mutate(
    week = parse_number(week)
  )
```

**d)** Which song stayed in the top 100 of the Billboard in 2000 for the most weeks? How many weeks did this song appear in the ranking? And which song stayed in the ranking for the least time?

```{r echo=FALSE, eval=FALSE}
billboard_longer |> 
  group_by(track) |> 
  summarise(n=n()) |> 
  arrange(desc(n)) 
```

**e)** Which song stayed exactly 10 weeks in the top 100 of the Billboard in 2000? If there is more than one song in this condition, consider the one that first entered the ranking.

```{r echo=FALSE, eval=FALSE}
billboard_longer |> 
  group_by(track, date.entered) |> 
  summarise(n=n()) |> 
  filter(n==10) |> 
  arrange(date.entered)
```

